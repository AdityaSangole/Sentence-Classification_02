{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "100c439d",
   "metadata": {},
   "source": [
    "\n",
    "## **Challenge Title**: Text Classification for Active vs. Passive Voice Detection \n",
    "**Objective:** Develop a text classification model that can effectively detect whether a\n",
    "given sentence is in the active or passive voice, using a dataset of labelled sentences.\n",
    "This challenge aims to assess your skills in natural language processing, machine\n",
    "learning, and model explainability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2830bfe5",
   "metadata": {},
   "source": [
    "**Name** : Aditya Sangole  \n",
    "**Contact** : +91 9637629918  \n",
    "**E-mail** : adityasangole12@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfee90e",
   "metadata": {},
   "source": [
    "**Workflow :**\n",
    "1. **Tokenization**:\n",
    "   - Tokenization is the process of splitting sentences into individual words or terms.\n",
    "   - Formula: None; it's a preprocessing step.\n",
    "\n",
    "2. **Term Frequency (TF)**:\n",
    "   - Calculate how often each term appears in a sentence.\n",
    "   - Formula: `TF(t, d) = (Number of times term t appears in document d) / (Total number of terms in document d)`\n",
    "\n",
    "3. **Inverse Document Frequency (IDF)**:\n",
    "   - Measure the importance of a term across the entire corpus.\n",
    "   - Formula: `IDF(t) = log((Total number of documents in the corpus) / (Number of documents containing term t))`\n",
    "\n",
    "4. **TF-IDF Calculation**:\n",
    "   - Compute the TF-IDF score for each term in each sentence.\n",
    "   - Formula: `TF-IDF(t, d) = TF(t, d) * IDF(t)`\n",
    "\n",
    "5. **Vectorization**:\n",
    "   - Create numeric vectors for each sentence using the TF-IDF scores.\n",
    "   - Each dimension in the vector corresponds to a unique term in the corpus.\n",
    "   - The value in each dimension represents the TF-IDF score of the corresponding term in the sentence.\n",
    "\n",
    "6. **Classification Model**:\n",
    "   - Feed the TF-IDF vectors into a classification model (e.g., logistic regression).\n",
    "   - The model learns to distinguish between active and passive voice sentences based on these vectors.\n",
    "<img src=\"WF.png\" width=\"300\"/>\n",
    "\n",
    "**Preprocessing Steps :** \n",
    "<img src=\"PPS.png\" width=\"200\" height=\"100\">\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8d3a288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import nltk #used for natural language processing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer #used for feature extraxtion from text\n",
    "from sklearn.model_selection import train_test_split #used to divide the data into training and testing\n",
    "#models we will apply for classification\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "884ad25c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>voice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The chef prepares the meal.</td>\n",
       "      <td>Active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The teacher explains the lesson clearly.</td>\n",
       "      <td>Active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The gardener waters the plants every morning.</td>\n",
       "      <td>Active</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                       sentence   voice\n",
       "0   1                    The chef prepares the meal.  Active\n",
       "1   2       The teacher explains the lesson clearly.  Active\n",
       "2   3  The gardener waters the plants every morning.  Active"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the data \n",
    "data=pd.read_csv('immverse_ai_eval_dataset (2)1.csv')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aacf7151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: voice, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#map the voice 0 as active and 1 as passive\n",
    "data['voice']=data['voice'].map({'Active': 0, 'Passive': 1})\n",
    "data['voice'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fadc0fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary libraries for preprocessing of the text sentence\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35e6d938",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function For preprocessing\n",
    "def pre_process(text) :\n",
    "    #tokenize the text received\n",
    "    tokens = word_tokenize(text)\n",
    "    #Remove Stopwords\n",
    "    stop_words=set(stopwords.words('english'))\n",
    "    filtered_tokens=[] #list which stores the tokens after the stop word removal\n",
    "    for word in tokens:\n",
    "        if word.lower() not in stop_words and word not in string.punctuation :\n",
    "            filtered_tokens.append(word)\n",
    "    #stemming of the word tokens using PorterStemmer()\n",
    "    stemmer=PorterStemmer()\n",
    "    stemmed_tokens=[] #list which stores the word tokens after the stemming process\n",
    "    for word in filtered_tokens:\n",
    "        stemmed_tokens.append(stemmer.stem(word))\n",
    "    #finaly return the stemmed token as a single text or sentence  \n",
    "    return (' '.join(stemmed_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab2e0f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divding the data into train(60%), Test (20%), and validation(20%)\n",
    "#We will divde the training data and test+validation data first\n",
    "#after we will split the training and validation data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,temp_data,y_train,temp_label=train_test_split(data['sentence'],data['voice'],test_size=0.4,random_state=40)\n",
    "X_test,X_valid,y_test,y_valid=train_test_split(temp_data,temp_label,test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00dae4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the prerocessing steps to train test and validation data\n",
    "X_train=X_train.apply(pre_process)\n",
    "X_test=X_test.apply(pre_process)\n",
    "X_valid=X_valid.apply(pre_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0244f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32          modern dress creat design\n",
       "30    film shot variou locat director\n",
       "14               programm code applic\n",
       "15           architect draw plan hous\n",
       "20                   meal prepar chef\n",
       "Name: sentence, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets check the training data after the preprocessing and stop word removal\n",
    "#apply the prerocessing steps to train test and validation data\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ca477ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#After the data is preprocessed we can apply the feature extraction to extract the features from our corpus \n",
    "#as vectores after we can use these vectors as numarical features to train our model to classify the sentences\n",
    "vectorizer=TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8d796ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=vectorizer.fit_transform(X_train)\n",
    "X_test=vectorizer.transform(X_test)\n",
    "X_valid=vectorizer.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb58c849",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets check the score for diffrent models we have by Hyperparameter tuning\n",
    "#for this we will use GridSearchCV() the GridSearchCV() will train each model on our pre processed data \n",
    "#and will return the score for each model or the model with highest accureacy(best suitale model)\n",
    "#let's create a following dictionry of models and thier parameters \n",
    "model_params = {\n",
    "    'svm': {\n",
    "        'model': SVC(),\n",
    "        'params' : {\n",
    "            'kernel': ['rbf','linear']\n",
    "        }  \n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(random_state=42),\n",
    "        'params' : {\n",
    "            'n_estimators': [5,10,15,100]\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression' : {\n",
    "        'model': LogisticRegression(),\n",
    "        'params': {\n",
    "        }\n",
    "    },\n",
    "    'KNN' : {\n",
    "        'model' :  KNeighborsClassifier(),\n",
    "        'params' : {\n",
    "            'n_neighbors' :[2,3,4,5,10,7]\n",
    "        }\n",
    "    },\n",
    "    'Decision_Tree' :{\n",
    "        'model' : DecisionTreeClassifier(),\n",
    "    'params':{\n",
    "        \n",
    "    }\n",
    "                     }\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b6e38c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n",
      "C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 668, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 810, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 6, n_neighbors = 10\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 668, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 810, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 6, n_neighbors = 10\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 668, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 810, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 6, n_neighbors = 10\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 668, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 810, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 6, n_neighbors = 10\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 668, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 810, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 6, n_neighbors = 7\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 668, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 810, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 6, n_neighbors = 7\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 668, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 810, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 6, n_neighbors = 7\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 444, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 668, in score\n",
      "    return accuracy_score(y, self.predict(X), sample_weight=sample_weight)\n",
      "                             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 234, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 810, in kneighbors\n",
      "    raise ValueError(\n",
      "ValueError: Expected n_neighbors <= n_samples,  but n_samples = 6, n_neighbors = 7\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.25 0.25 0.25 0.75  nan  nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\adity\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.75</td>\n",
       "      <td>{'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.75</td>\n",
       "      <td>{'n_estimators': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.75</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.75</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>0.25</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  best_score           best_params\n",
       "0                  svm        0.75     {'kernel': 'rbf'}\n",
       "1        random_forest        0.75  {'n_estimators': 15}\n",
       "2  logistic_regression        0.75                    {}\n",
       "3                  KNN        0.75    {'n_neighbors': 5}\n",
       "4        Decision_Tree        0.25                    {}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "scores=[] #list which stores the models with resective bestscore and parameters\n",
    "for model_names,mp in model_params.items() :\n",
    "    mod =  GridSearchCV(mp['model'], mp['params'], cv=4, return_train_score=False)\n",
    "    mod.fit(X_valid, y_valid)\n",
    "    scores.append({\n",
    "        'model': model_names,\n",
    "        'best_score': mod.best_score_,\n",
    "        'best_params': mod.best_params_\n",
    "    })\n",
    "df = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46fe9bc",
   "metadata": {},
   "source": [
    "As the data is so small the validation set is also very less thus we can use the hypertuning directly on the tarining data for the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec9854a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>{'kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>{'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>{'n_neighbors': 4}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  best_score          best_params\n",
       "0                  svm    0.250000    {'kernel': 'rbf'}\n",
       "1        random_forest    0.291667  {'n_estimators': 5}\n",
       "2  logistic_regression    0.250000                   {}\n",
       "3                  KNN    0.458333   {'n_neighbors': 4}\n",
       "4        Decision_Tree    0.208333                   {}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using hypertuning on training data \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "scores1=[] #list which stores the models with resective bestscore and parameters\n",
    "for model_names,mp in model_params.items() :\n",
    "    mod =  GridSearchCV(mp['model'], mp['params'], cv=4, return_train_score=False)\n",
    "    mod.fit(X_train, y_train) #directly using training data\n",
    "    scores1.append({\n",
    "        'model': model_names,\n",
    "        'best_score': mod.best_score_,\n",
    "        'best_params': mod.best_params_\n",
    "    })\n",
    "df1 = pd.DataFrame(scores1,columns=['model','best_score','best_params'])\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd040373",
   "metadata": {},
   "source": [
    "As we can see in above table or dataframe the  k-nearest neighbors model giving us the maximum score of 45% (may vary) and decison tree giving us minimum score of 29% so we will use KNN algoritham model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de71990d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=4)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=4)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating instace of knn model\n",
    "model=KNeighborsClassifier(n_neighbors=4)\n",
    "#fit the model on the traning data \n",
    "model.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23656fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "486da690",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function for taking new input preprocess it and produce the output\n",
    "def pred(text):\n",
    "    #i=input(\"Enter your sentence : \")\n",
    "    input_text=pre_process(text)\n",
    "    input_text_vector=vectorizer.transform([input_text])\n",
    "    a=model.predict(input_text_vector)\n",
    "    if a==0 :\n",
    "        return \"Active Voice\"\n",
    "    elif a==1 :\n",
    "        return \"Passive Voice\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fab9d4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your sentence : The cake was eaten by John.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Passive Voice'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prediction for the new input sentence\n",
    "i=input(\"Enter your sentence : \")\n",
    "if(i==''):\n",
    "    print('Please Input a sentence!')\n",
    "pred(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3928edbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets take 10 passive sentences and find the result\n",
    "passive_voice_sentences = [\n",
    "    \"The cake was eaten by John.\",\n",
    "    \"The book was read by her.\",\n",
    "    \"The car was driven by my father.\",\n",
    "    \"The letter was written by Susan.\",\n",
    "    \"The house was built by the construction workers.\",\n",
    "    \"The movie was watched by a large audience.\",\n",
    "    \"The song was sung by the famous singer.\",\n",
    "    \"The problem was solved by the team of engineers.\",\n",
    "    \"The report was reviewed by the supervisor.\",\n",
    "    \"The painting was admired by art enthusiasts.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "093901ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passive Voice\n",
      "Passive Voice\n",
      "Passive Voice\n",
      "Passive Voice\n",
      "Active Voice\n",
      "Passive Voice\n",
      "Passive Voice\n",
      "Active Voice\n",
      "Active Voice\n",
      "Active Voice\n"
     ]
    }
   ],
   "source": [
    "for sent in passive_voice_sentences :\n",
    "    print(pred(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec4dd4d",
   "metadata": {},
   "source": [
    "# model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9945f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries and modules for the model performace test\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3eabd0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7bdccb42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.83      0.77         6\n",
      "           1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.62         8\n",
      "   macro avg       0.36      0.42      0.38         8\n",
      "weighted avg       0.54      0.62      0.58         8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_rep =classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6967a67",
   "metadata": {},
   "source": [
    "1. **Precision (Active Voice)**: The precision for classifying sentences as active voice is 0.50, meaning that 50% of the sentences predicted as active voice were correct.\n",
    "\n",
    "2. **Precision (Passive Voice)**: The precision for classifying sentences as passive voice is 0.00, indicating that none of the sentences predicted as passive voice were actually in passive voice.\n",
    "\n",
    "3. **Recall (Active Voice)**: The recall for classifying sentences as active voice is 1.00, which means all actual active voice sentences were correctly identified.\n",
    "\n",
    "4. **Recall (Passive Voice)**: The recall for classifying sentences as passive voice is 0.00, implying that none of the actual passive voice sentences were captured by the model.\n",
    "\n",
    "5. **F1-Score (Active Voice)**: The F1-Score for classifying sentences as active voice is 0.67, indicating moderate performance in identifying active voice sentences.\n",
    "\n",
    "6. **F1-Score (Passive Voice)**: The F1-Score for classifying sentences as passive voice is 0.00, reflecting poor performance in identifying passive voice sentences.\n",
    "\n",
    "7. **Support (Active Voice)**: There are 4 actual active voice sentences in the test set.\n",
    "\n",
    "8. **Support (Passive Voice)**: There are 4 actual passive voice sentences in the test set.\n",
    "\n",
    "9. **Accuracy**: The overall accuracy of the model is 50%, suggesting that half of the sentences were correctly classified as either active or passive voice.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec8df13",
   "metadata": {},
   "source": [
    "**Analysis of the Model's Strengths and Areas for Improvement:**\n",
    "\n",
    "The model demonstrates a moderate level of performance, achieving an accuracy of approximately 50-60%, considering the limited dataset available. This level of accuracy is reasonable for the data volume provided.\n",
    "\n",
    "One significant area for improvement is the amount of data. Increasing the volume of data is likely to enhance the model's performance. With a larger and more diverse dataset, the model can learn better representations and generalize more effectively.\n",
    "\n",
    "Additionally, exploring alternative classification methods, such as Naive Bayes and others, may lead to performance improvements. Experimenting with different algorithms can help identify the one that suits the task best.\n",
    "\n",
    "One notable limitation of the current model is the limited vocabulary available for making correct classifications. Addressing this data constraint by incorporating a more extensive vocabulary can significantly enhance the model's accuracy.\n",
    "\n",
    "Furthermore, hyperparameter tuning techniques, such as Randomized Search and cross-validation, can be employed to fine-tune the model's performance. These techniques can help optimize hyperparameters and improve overall model effectiveness.\n",
    "\n",
    "In summary, while the model exhibits moderate performance with the given data, there are several avenues for enhancement, including increasing data volume, exploring alternative algorithms, expanding the vocabulary, and utilizing hyperparameter tuning methods. These efforts can collectively lead to improved model accuracy and effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63adc014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained KNN model\n",
    "with open('knn_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)\n",
    "\n",
    "# Save the TF-IDF vectorizer\n",
    "with open('vectorizer.pkl', 'wb') as vec_file:\n",
    "    pickle.dump(vectorizer, vec_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "170cf14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Calculate accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Save the accuracy score\n",
    "with open('accuracy_score.pkl', 'wb') as acc_file:\n",
    "    pickle.dump(accuracy, acc_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b0294cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Calculate classification report\n",
    "y_pred = model.predict(X_test)\n",
    "classification_rep = classification_report(y_test, y_pred, target_names=['Active', 'Passive'])\n",
    "\n",
    "# Save classification report to a text file\n",
    "with open('classification_report.txt', 'w') as file:\n",
    "    file.write(classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d409b86c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
